{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습 (CNN) \n",
    "https://hunkim.github.io/ml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ba885c9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array([[[[1], [2], [3]],\n",
    "                    [[4], [5], [6]],\n",
    "                    [[7], [8], [9]]]],dtype=np.float32)\n",
    "image.shape\n",
    "# 4차원으로 데이터 준비\n",
    "\n",
    "# 숫자를 이미지로 시각화\n",
    "plt.imshow(image.reshape(3,3),cmap=\"Grays\") # 2차원으로 넘겨줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TensorShape' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9e1c33d89463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 4차원으로 해야 함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# conv2d = tf.nn.conv2d(image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorShape' object is not callable"
     ]
    }
   ],
   "source": [
    "# padding없이 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[[1.]], [[1.]]], \n",
    "                       [[[1.]], [[1.]]]]]) # 4차원으로 해야 함\n",
    "filter.shape()\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1,1,1,1], padding=\"SAME\") \n",
    "# SAME: 가로세로 똑같이 \n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    one_img.reshpae(3,3)\n",
    "    plot.subplot(1,2,i+1)\n",
    "    plot.imshow(one_img.reshape(3,3), cmap=\"Grays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 필터 사용(2*2*1*3)\n",
    "\n",
    "filter = tf.constant([[[[[1.,10, -1]], [[1., 1-, -1]]], \n",
    "                       [[[1.,10, -1]], [[1.,10, -1]]]]]) # 4차원으로 해야 함\n",
    "filter.shape()\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1,1,1,1], padding=\"SAME\") \n",
    "# SAME: 가로세로 똑같이 \n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    one_img.reshpae(3,3)\n",
    "    plot.subplot(1,3,i+1)\n",
    "    plot.imshow(one_img.reshape(3,3), cmap=\"Grays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPooling(2*2)\n",
    "\n",
    "image2 = tf.constant([[[[4],[3]],\n",
    "                      [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1,2,2,1], strides=[1,1,1,1],\n",
    "                     padding=\"VALID\") # 앞뒤 1은 모양 맞추기 위한 것\n",
    "                                                # 실제 값은 가운데 2, 2이다.\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST를 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_set(\"../Acorn machine learining/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "img = mnist.train.images[0]\n",
    "img.shape\n",
    "plt.imshow(img,reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 준비 \n",
    "X = tf.placeholder(tf.float32, shape=[None,784])\n",
    "y = tf.placeholder(tf.float32, shape=[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first Convolution layer 준비\n",
    "\n",
    "# 필터(가중치) : 크기는 3*3, 개수는 32, 색상은 1\n",
    "# 텐서에 이미지를 4차원으로 넣어줘야 한다.\n",
    "# 28*28 크기의 4차원 데이터로 만듬\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28,28, 1]) # 1차원 --> 4차원,\n",
    "# 28x28x1 행렬을 무한개수(-1)로 정의\n",
    "W1 = tf.variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "# stddev=0.01 랜덤 범위 지정, 3*3크기에 색상 1, 개수 32개 만듬\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME') \n",
    "# padding안 할 때는 VALID\n",
    "print(L1)\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "\n",
    "# pooling 작업\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") \n",
    "# ksize=[1,2,2,1] :필터는 2*2크기로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second Convolution layer 준비\n",
    "# 필터 : 크기는 3*3, 개수 : 64개 색상 : 1\n",
    "\n",
    "W2 = tf.variable(tf.random_normal([3,3,32,64], stddev=0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME') \n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") \n",
    "print(L2) # 최종 입력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Fully Connected Layer (Dense Layer)===============\n",
    "\n",
    "# hyper parameter 준비\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "#  tensorflow graph 작성\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64]) # 입력데이터 2차원으로 맞춰서 넣어줘야 한다.\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 비용(loss) 계산\n",
    "logit = tf.matmul(L2, W3) + b3\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용(loss) 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimizer(cost)\n",
    "\n",
    "# === tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict = {X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(\"Epoch :\",\"%0.4d\"%(epoch + 1), \"cost=\",\"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(logit,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 :\", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                            y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep FC\n",
    "\n",
    "+ 레이어 총 3개 사용, 입출력 개수 128개 사용\n",
    "+ xavier 초기화\n",
    "+ dropout 사용\n",
    "+ training_epoch : 15\n",
    "+ batch_size : 100\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "### 첫번째 레이어\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([128]))\n",
    "logit3 = tf.matmul(L3, W3) + b3\n",
    "L3 = tf.nn.relu(logit3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=prob)\n",
    "\n",
    "### 두번째 레이어\n",
    "W4 = tf.get_variable(\"W4\", shape=[128, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128]))\n",
    "logit4 = tf.matmul(L3, W4) + b4\n",
    "L4 = tf.nn.relu(logit4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=prob)\n",
    "\n",
    "### 세번째 레이어\n",
    "W5 = tf.get_variable(\"W5\", shape=[128, 10], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logit5 = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit5,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys,\n",
    "                                                 prob:0.7})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "   \n",
    "\n",
    " ### 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit5, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                             y:mnist.test.labels, prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 표지판 인식\n",
    "+ http://benchmark.ini.rub.de\n",
    "\n",
    "+ 이미지(32*32) --> conv Layer1(pooling) --> Conv Layer2(pooling) --> FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.color import rgb2lab # rgb2lab :색상 단순화\n",
    "from skimage.transform import resize # 이미지 크기 조정\n",
    "from collections import namedtuple\n",
    "np.random.seed(101) # 랜덤값 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "\n",
    "N_CLASSES = 43\n",
    "RESIZED_IMAGE = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'index',\n",
       " 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 y는 43개\n",
    "\n",
    "Dataset = namedtuple(\"Dataset\", [\"X\", \"y\"]) # X, y 추가\n",
    "dir(Dataset)\n",
    "# namedtuple : dict와 같은 기능이나 읽기 전용이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 1)\n",
      "(39209, 43)\n"
     ]
    }
   ],
   "source": [
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n",
    "    # 열기준으로 stack을 이용하여 쌓아줌  \n",
    "    # images = imgs, \n",
    "\n",
    "# 이미지 크기를 재조정하고 색상은 회색조로 변경, 원핫인코딩\n",
    "def read_dataset_ppm(rootpath, n_labels, resized_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for c in range(n_labels):\n",
    "        full_path = rootpath + \"/\" + format(c, '05d') + \"/\"\n",
    "        # 0으로 5자리 채우고 c 더함\n",
    "        # print(full_path)\n",
    "        for img_name in glob.glob(full_path +\"*.ppm\"): # 폴더 안 파일 개수만큼 반복 \n",
    "            img = plt.imread(img_name).astype(np.float32) # 이미지를 숫자로 읽어옴\n",
    "            # print(img)\n",
    "            # break\n",
    "            img = rgb2lab(img/255.0)[:, :, 0] # rgb 색상을 lab형으로 변경\n",
    "            # print(img) # 값이 전보다 작아진것을 확인\n",
    "            # break\n",
    "            \n",
    "            img = resize(img, resized_to, mode=\"reflect\") \n",
    "            # 크기 바꿀 이미지 넘겨주고, 이미지 크기, 모드는 reflect로 \n",
    "            \n",
    "            label = np.zeros((n_labels,),dtype=np.float32)\n",
    "            label[c] = 1.0 # c에 해당하는 자리에만 1로 채우고 나머지 0으로\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "            \n",
    "    return Dataset(X=to_tf_format(images), y=np.array(labels)) \n",
    "                    # X값을 4차원으로 받기 \n",
    "\n",
    "ds = read_dataset_ppm(\"../Acorn machine learning/GTSRB/Final_Training/Images\",\n",
    "                N_CLASSES, RESIZED_IMAGE)\n",
    "\n",
    "print(ds.X.shape)\n",
    "print(ds.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(ds.X[0,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ds.X[-1,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29406, 32, 32, 1)\n",
      "(9803, 32, 32, 1)\n",
      "(29406, 43)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_teset, y_train,y_test = train_test_split(range(ds.X.shape[0]), ds.y, \n",
    "#                                                    test_size=0.25, \n",
    "#                                                    random_state=101)\n",
    "# np.array(X_train).shape \n",
    "# \n",
    "# 위에 방법이 아닌 아래의 방법으로 학습데이터를 분리한다.\n",
    "idx_train, idx_test = train_test_split(range(ds.X.shape[0]), test_size=0.25, \n",
    "                                       random_state=101)\n",
    "                                                   \n",
    "X_train = ds.X[idx_train, :, :, :]                                                   \n",
    "X_test = ds.X[idx_test, :, :, :]\n",
    "y_train =  ds.y[idx_train, :] \n",
    "y_test =  ds.y[idx_test, :] \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련(학습)과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니ㅣ배치 준비\n",
    "\n",
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0] # assert : \n",
    "    n_samples = X.shape[0] # 29406개의 데이터 가져옴\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples) # 데이터 인덱스 순서를 바꿔줌\n",
    "        \n",
    "    else:\n",
    "        idx = list(range(n_samples))\n",
    "        \n",
    "    for i in range(int(np.ceil(n_samples/batch_size))): \n",
    "        # ceil은 소수점 자리의 숫자를 무조건 올리는 함수\n",
    "        from_idx = i * batch_size\n",
    "        to_idx = (i + 1) * batch_size # 0~10000, 10001~20000, 20001~나머지\n",
    "        \n",
    "        yield X[idx[from_idx : to_idx], :, :, :], y[idx[from_idx : to_idx], :]\n",
    "        # yield : return과 비슷하나 반환할 값이 아예 없을 때까지 계속 같은 과정을 반복\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 함수 테스트\n",
    "for  i in minibatcher(X_train, y_train, 10000, True): \n",
    "    print(i[0].shape, i[1].shape)\n",
    "# 배치 사이즈 10000개, True는 데이터를 섞어 준다는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_ro_activation_layer(in_tensors, n_units):\n",
    "    W = tf.get_variable(\"fc_W\", shape=[in_tensors.get_shape()[1],n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"fc_b\", shape=[n_units],\n",
    "                        initializer=tf.constant_initializer(0,0)) # 0 으로 초기화\n",
    "    \n",
    "    return tf.matmul(in_tensors,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(in_tensors, n_units):\n",
    "    return tf.nn.leaky_relu(fc_ro_activation_layer(in_tensors, n_units))\n",
    "    # leaky_relu :0보다 작은 값도 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units): # convolution layer\n",
    "    # kernel_size :filter 크기\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size,kernel_size,\n",
    "                                  in_tensors.get_shape()[3], n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"fc_b\", shape=[n_units],\n",
    "                        initializer=tf.constant_initializer(0,0)) # 0 으로 초기화\n",
    "    return tf.nn.conv2d(in_tensors, W, strides=[1,1,1,1], padding='SAME') + b \n",
    "\n",
    "#*****패딩이란\n",
    "# 입력된 데이타 행렬 주위로, 무의미한 값을 감싸서 원본 데이터의 \n",
    "# 크기를 크게 해서, 필터를 거치고 나온 특징 행렬의 크기가 작아지는 것을 방지한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(in_tensors, sampling):\n",
    "    return tf.nn.max_pool(in_tensors, ksize=[1,sampling,sampling,1],\n",
    "                          strides=[1,sampling,sampling,1], padding=\"SMAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(in_tensors, keep_prob, is_training): \n",
    "    # is_training :훈련중인지 아닌지 구별할 인자\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors,keep_prob),\n",
    "                  lambda:in_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specitication\n",
    "\n",
    "+ 2차원 convolution 5 * 5, 32 필터\n",
    "+ 2차원 convolution 5 * 5, 64 필터\n",
    "+ 평면화 계층 \n",
    "+ Full Connected Layer, 입출력 개수 : 1024개의 unit\n",
    "+ Dropout 40%\n",
    "+ Softamx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링\n",
    "\n",
    "def model(intensors, is_training):\n",
    "    # First Layer : 5*5 Convolution layer, 32개 필터, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = conv_layer(in_tensors, kernel_size=5, n_units=32)\n",
    "        l1 = maxpool_layer(l1, 2) # sampling = 2\n",
    "        # 한줄 코드\n",
    "        # 1l = maxpool_layer(conv_layer(in_tensors, 5, 32),2)\n",
    "        l2_out = dropout(l1, 0.8, is_training)\n",
    "        \n",
    "    # Secon Layer: 5*5 Convolution layer, 64개 필터, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(in_tensors, 5, 64),2)\n",
    "        l2_out = dropout(l2,0.8, is_training)\n",
    "        \n",
    "    # Flat Layer : 평면화\n",
    "    with tf.variable_scope(\"flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out)\n",
    "    \n",
    "    \n",
    "    # Fully Connected Layer, 1024 neurons, 40% dropot\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, n_units=1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "        \n",
    "    # Output\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        out_tensors = fc_ro_activation_layer(l3_out, N_CLASSES) # N_CLASSES은 위에 43이라고 정의\n",
    "        \n",
    "    return out_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, learning_rate, max_epochs, batch_size):\n",
    "    # in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None,32,32,1))\n",
    "    # shape=[] 사용가능\n",
    "    \n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None,RESIZED_IMAGE[0],\n",
    "                                                           RESIZE_IMAGE[1],1))\n",
    "    # 훈련데이터 : 29406개수 정해주거나 None, 원본 크기: 32*32, 색상 : 1\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape=(None, N_CLASSES))\n",
    "    \n",
    "    # 훈련 여부\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    # 모델함수 호출\n",
    "    logit = model(in_X_tensors_batch, is_training)\n",
    "    \n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=in_y_tensors_batch))\n",
    "\n",
    "    # 최저 비용 구하기\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variable_initializer())\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(\"Epoch = \", epoch)\n",
    "            tf_score = []\n",
    "            \n",
    "            for mb in minibatcher(X_train, y_train,batch_size, shuffle=True):\n",
    "                sess.run([train, cost], feed_dict={in_X_tensors_batch : mb[0],\n",
    "                                                   in_y_tensors_batch :mb[1],\n",
    "                                                   is_training:True})\n",
    "                tf_score.append(c)\n",
    "                \n",
    "            print(\"train loss score : \",np.mean(tf._score))\n",
    "            \n",
    "        # 훈련이 끝난 후 테스트\n",
    "        print(\"TEST SET PERFORMANCE\")\n",
    "\n",
    "        out_y_pred = tf.nn.softmax(logit) # 예측값 : ligit\n",
    "        sess.run([out_y_pred, cost], feed_dict={in_X_tensors_batch : X_test,\n",
    "                                    in_y_tensors_batch : y_test,\n",
    "                                    is_training:False})\n",
    "        print(\" test_loss_score=\", test_cost)\n",
    "        y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n",
    "        y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n",
    "        print(classification_report(y_test_true_classified, y_test_pred_classified))\n",
    "\n",
    "        cm = confusion_matrix(y_test_true_classified, y_test_pred_classified)\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # And the log2 version, to enphasize the misclassifications\n",
    "        plt.imshow(np.log2(cm + 1), interpolation='nearest', cmap=plt.get_cmap(\"tab20\"))\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-e330e272c7f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 훈련데이터, learning_rate, max_epochs, batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # tensorflow 1.x버전에서만 작동됨\n",
    "train_model(X_train, y_train, 0.001, 10, 256) \n",
    "# 훈련데이터, learning_rate, max_epochs, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 일부 CNN, FC계층을 추가/삭제를 통해서 성능이 어떻게 변하는지 확인\n",
    "2. dropout의 비율을 변경해보면서 결과가 과소적합 또는 과대적합 되는지 확인\n",
    "3. epoch 개수와 batch size도 변경해서 결과 확인\n",
    "4. 실제 테스트 이지를 통해 사용할 수 있는 프로그램\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
