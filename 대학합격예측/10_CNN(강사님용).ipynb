{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플1 : 3 * 3 * 1 * 1 이미지 준비, 2 * 2 * 1 필터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([[[[1], [2], [3]], \n",
    "                   [[4], [5], [6]],\n",
    "                   [[7],[8], [9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding없이 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2, 2))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(2,2), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding을 이용한 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 필터 사용(2*2*1*3)\n",
    "\n",
    "filter = tf.constant([[[[1., 10, -1]], [[1., 10, -1]]], \n",
    "                      [[[1., 10, -1]], [[1., 10, -1]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i , one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPooling(2*2), padding 없이\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]], \n",
    "                       [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], \n",
    "                     padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPooling(2*2), padding 사용\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]], \n",
    "                       [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], \n",
    "                     padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST를 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-91728e189d13>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "img = mnist.train.images[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 입력값 준비\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수는 32, 색상수는 1\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 두 번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수 64, 색상수는 1\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Fully Connected Layer (Dense Layer) #################\n",
    "\n",
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "### tensor graph 작성\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 비용 계산\n",
    "logit = tf.matmul(L2, W3) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                             y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep FC\n",
    "\n",
    "+ 레이어 총 3개 사용, 입출력 갯수 128개 사용\n",
    "+ xavier 초기화\n",
    "+ dropout 사용\n",
    "+ training_epoch : 15\n",
    "+ batch_size : 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.466600628\n",
      "Epoch: 0002 cost= 0.148043171\n",
      "Epoch: 0003 cost= 0.108409341\n",
      "Epoch: 0004 cost= 0.088602800\n",
      "Epoch: 0005 cost= 0.071219196\n",
      "Epoch: 0006 cost= 0.063818301\n",
      "Epoch: 0007 cost= 0.055499472\n",
      "Epoch: 0008 cost= 0.048639586\n",
      "Epoch: 0009 cost= 0.043806544\n",
      "Epoch: 0010 cost= 0.041516048\n",
      "Epoch: 0011 cost= 0.035260138\n",
      "Epoch: 0012 cost= 0.034086327\n",
      "Epoch: 0013 cost= 0.029076980\n",
      "Epoch: 0014 cost= 0.028816646\n",
      "Epoch: 0015 cost= 0.025584352\n",
      "정확도 :  0.9908\n"
     ]
    }
   ],
   "source": [
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "### 첫번째 레이어\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([128]))\n",
    "logit3 = tf.matmul(L3, W3) + b3\n",
    "L3 = tf.nn.relu(logit3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=prob)\n",
    "\n",
    "### 두번째 레이어\n",
    "W4 = tf.get_variable(\"W4\", shape=[128, 128], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128]))\n",
    "logit4 = tf.matmul(L3, W4) + b4\n",
    "L4 = tf.nn.relu(logit4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=prob)\n",
    "\n",
    "### 세번째 레이어\n",
    "W5 = tf.get_variable(\"W5\", shape=[128, 10], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logit5 = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit5,\n",
    "                                                                labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys,\n",
    "                                                 prob:0.7})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "   \n",
    "\n",
    " ### 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit5, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                             y:mnist.test.labels, prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 표지판 인식\n",
    "\n",
    "+ https://benchmark.ini.rub.de/gtsrb_dataset.html\n",
    "    + GTSRB_Final_Test_Images.zip\n",
    "    + GTSRB_Final_Training_Images.zip\n",
    "    \n",
    "    \n",
    "+ 이미지(32 * 32) > Conv Layer1(Pooling) > Conv Layer2(Pooling) > FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.transform import resize\n",
    "from collections import namedtuple\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "N_CLASSES = 43\n",
    "RESIZED_IMAGE = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'index',\n",
       " 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = namedtuple(\"Dataset\", [\"X\", 'y'])\n",
    "dir(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 1)\n",
      "(39209, 43)\n"
     ]
    }
   ],
   "source": [
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n",
    "\n",
    "# 이미지 크기를 재조정하고 색상은 회색조로 변경, one-hot encoding\n",
    "def read_dataset_ppm(rootpath, n_labels, resize_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for c in range(n_labels):\n",
    "        full_path = rootpath + \"/\" + format(c, '05d') + \"/\"\n",
    "        \n",
    "        for img_name in glob.glob(full_path + \"*.ppm\"):\n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "            img = rgb2lab(img/255.0)[:, :, 0]\n",
    "            \n",
    "            img = resize(img, resize_to, mode=\"reflect\")\n",
    "            \n",
    "            label = np.zeros((n_labels,), dtype=np.float32 )\n",
    "            label[c] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "\n",
    "    return Dataset(X=to_tf_format(images), y=np.array(labels))\n",
    "#------------------------------------\n",
    "ds = read_dataset_ppm(\"data/GTSRB/Final_Training/Images\", N_CLASSES, \n",
    "                      RESIZED_IMAGE)\n",
    "\n",
    "print(ds.X.shape)\n",
    "print(ds.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(ds.X[0,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[0, :])\n",
    "\n",
    "plt.imshow(ds.X[-1,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29406, 32, 32, 1)\n",
      "(9803, 32, 32, 1)\n",
      "(29406, 43)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test= train_test_split(range(ds.X.shape[0]), \n",
    "#                                                   ds.y, test_size=0.25, \n",
    "#                                                   random_state=101)\n",
    "\n",
    "#np.array(X_train).shape\n",
    "\n",
    "idx_train, idx_test= train_test_split(range(ds.X.shape[0]), test_size=0.25, \n",
    "                                      random_state=101)\n",
    "\n",
    "X_train = ds.X[idx_train, :, :, :]\n",
    "X_test = ds.X[idx_test, :, :, :]\n",
    "y_train = ds.y[idx_train, :]\n",
    "y_test = ds.y[idx_test, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련(학습)과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 미니배치 준비\n",
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        idx = list(range(n_samples))\n",
    "        \n",
    "    for i in range(int(np.ceil(n_samples/batch_size))):\n",
    "        from_idx = i * batch_size\n",
    "        to_idx = (i+1) * batch_size\n",
    "        yield X[idx[from_idx : to_idx], :, :, :], y[idx[from_idx : to_idx], :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "### 미니배치 함수 테스트\n",
    "for i in minibatcher(X_train, y_train, 10000, True):\n",
    "    print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_no_activation_layer(in_tensors, n_units):\n",
    "    W = tf.get_variable(\"fc_W\", shape=[in_tensors.get_shape()[1], n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"fc_b\", shape=[n_units],\n",
    "                       initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.matmul(in_tensors, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(in_tensors, n_units):\n",
    "    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size, kernel_size, \n",
    "                                  in_tensors.get_shape()[3], n_units], \n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"conv_b\", shape=[n_units],\n",
    "                       initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.nn.leaky_relu(tf.nn.conv2d(in_tensors, W, [1, 1, 1, 1], \"SAME\") + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(in_tensors, sampling):\n",
    "    return tf.nn.max_pool(in_tensors, [1, sampling, sampling, 1], \n",
    "                          [1, sampling, sampling, 1], \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(in_tensors, keep_proba, is_training):\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors, keep_proba),\n",
    "                  lambda:in_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "\n",
    "+ 2차원 convolution 5 * 5, 32 필터\n",
    "+ 2차원 convolution 5 * 5, 64 필터\n",
    "+ 평면화 계층(Flat Layer)\n",
    "+ Full Connected Layer, 1024개의 unit\n",
    "+ Dropout 40%\n",
    "+ Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(in_tensors, is_training):\n",
    "    # First Layer : 5*5 2d convolution layer, 32filters, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n",
    "        l1_out = dropout(l1, 0.8, is_training)\n",
    "    \n",
    "    # Second Layer : 5*5 2d conv layer, 64filters, 2x maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(in_tensors, 5, 64), 2)\n",
    "        l2_out = dropout(l2, 0.8, is_training)\n",
    "        \n",
    "    # Flat Layer\n",
    "    with tf.variable_scope(\"flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out)\n",
    "        \n",
    "    # Fully Connected Layer, 1024 neurons, 40% dropout\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, 1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "        \n",
    "    # output\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        out_tensors = fc_no_activation_layer(l3_out, N_CLASSES)\n",
    "    \n",
    "    return out_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, learning_rate, max_epochs, batch_size):\n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None, \n",
    "                                                           RESIZED_IMAGE[0],\n",
    "                                                           RESIZED_IMAGE[1],1))\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape=(None, N_CLASSES))\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    logit = model(in_X_tensors_batch, is_training)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                labels=in_y_tensors_batch))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(\"Epoch=\", epoch)\n",
    "            tf_score = []\n",
    "            \n",
    "            for mb in minibatcher(X_train, y_train, batch_size, shuffle=True):\n",
    "                _, c = sess.run([train, cost], \n",
    "                                feed_dict={in_X_tensors_batch:mb[0],\n",
    "                                                  in_y_tensors_batch:mb[1],\n",
    "                                                  is_training:True})\n",
    "                tf_score.append(c)\n",
    "                \n",
    "            print(\" train loss score=\", np.mean(tf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-26-207eb419253a>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-27-aa0ac3f1fe9a>:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Epoch= 0\n",
      " train loss score= 12.312093\n",
      "Epoch= 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-331d485a3f76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-1b4b3b459522>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, learning_rate, max_epochs, batch_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m                                 feed_dict={in_X_tensors_batch:mb[0],\n\u001b[0;32m     24\u001b[0m                                                   \u001b[0min_y_tensors_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                                                   is_training:True})\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mtf_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, 0.001, 10, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
