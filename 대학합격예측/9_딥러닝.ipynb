{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [1], [1], [1], ,[1], [1], [1], [1]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1])tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X , W) + b)\n",
    "cost = tf.reduce_mean(y * tf.log*(hypot) + (1-y)*tf.log(1-hypot))\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-1518be850059>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1518be850059>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    for step in range(1000):\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a = aess.run([train, hypot, pred, accuracy],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [0], [0], [0], ,[0], [0], [0], [1]],dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1])tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X , W) + b)\n",
    "cost = tf.reduce_mean(y * tf.log*(hypot) + (1-y)*tf.log(1-hypot))\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a = aess.run([train, hypot, pred, accuracy],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [1], [1], [1], [1], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1])tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X , W) + b)\n",
    "cost = tf.reduce_mean(y * tf.log*(hypot) + (1-y)*tf.log(1-hypot))\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.cast(hypot > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a = aess.run([train, hypot, pred, accuracy],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]]\n",
    "\n",
    "y_data = [0, 1, 1, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=100)\n",
    "clf.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "examples = [[0,0,0], [1, 1, 1],[0, 1, 0], [1, 1, 0]]\n",
    "examples_label = [0, 0, 1, 1]\n",
    "\n",
    "result = clf.predict(examples)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(examples_label, result)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딥러닝을 이용한 XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [1], [1], [1], [1], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "# 입력값 : X, y\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# 레이어 1\n",
    "W1 = tf.Variable(tf.random_normal([3,10])tf.float32, name=\"Weight1\") # 3개 입력 10개 출력\n",
    "b1 = tf.Variable(tf.random_normal([10])tf.float32, name=\"bias1\")     # 출력의 개수는 적절하게 튜닝\n",
    "hypot1 = tf.sigmoid(tf.matmul(X , W1) + b1)\n",
    "\n",
    "# 레이어 2\n",
    "W2 = tf.Variable(tf.random_normal([10,1])tf.float32, name=\"Weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias2\")\n",
    "hypot2 = tf.sigmoid(tf.matmul(hypot1 , W2) + b2)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(y * tf.log*(hypot2) + (1-y)*tf.log(1-hypot2))\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 예측\n",
    "pred = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a = aess.run([train, hypot, pred, accuracy],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wide & deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어수는 7개, 입출력  연결의 수는 50개로 구현\n",
    "\n",
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [1], [1], [1], [1], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "# 입력값 : X, y\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# 레이어 1\n",
    "W1 = tf.Variable(tf.random_normal([3,50])tf.float32, name=\"Weight1\") # 3개 입력 10개 출력\n",
    "b1 = tf.Variable(tf.random_normal([50])tf.float32, name=\"bias1\")     # 출력의 개수는 적절하게 튜닝\n",
    "hypot1 = tf.sigmoid(tf.matmul(X , W1) + b1)\n",
    "\n",
    "# 레이어 2\n",
    "W2 = tf.Variable(tf.random_normal([10,1])tf.float32, name=\"Weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias2\")\n",
    "hypot2 = tf.sigmoid(tf.matmul(hypot1 , W2) + b2)\n",
    "\n",
    "\n",
    "# 레이어 3\n",
    "W3 = tf.Variable(tf.random_normal([50,50])tf.float32, name=\"Weight3\") # 3개 입력 10개 출력\n",
    "b3 = tf.Variable(tf.random_normal([50])tf.float32, name=\"bias3\")     # 출력의 개수는 적절하게 튜닝\n",
    "hypot3 = tf.sigmoid(tf.matmul(hypot2 , W1) + b1)\n",
    "\n",
    "# 레이어 4\n",
    "W4 = tf.Variable(tf.random_normal([50,50])tf.float32, name=\"Weight4\")\n",
    "b4 = tf.Variable(tf.random_normal([50])tf.float32, name=\"bias4\")\n",
    "hypot4 = tf.sigmoid(tf.matmul(hypot3 , W2) + b2)\n",
    "\n",
    "# 레이어 5\n",
    "W5 = tf.Variable(tf.random_normal([50,50])tf.float32, name=\"Weight5\") # 3개 입력 10개 출력\n",
    "b5 = tf.Variable(tf.random_normal([50])tf.float32, name=\"bias5\")     # 출력의 개수는 적절하게 튜닝\n",
    "hypot5 = tf.sigmoid(tf.matmul(hypot4 , W1) + b1)\n",
    "\n",
    "# 레이어 6\n",
    "W6 = tf.Variable(tf.random_normal([50,50])tf.float32, name=\"Weight6\")\n",
    "b6 = tf.Variable(tf.random_normal([50])tf.float32, name=\"bias6\")\n",
    "hypot6 = tf.sigmoid(tf.matmul(hypot5 , W2) + b2)\n",
    "\n",
    "# 레이어 7\n",
    "W7 = tf.Variable(tf.random_normal([50,1])tf.float32, name=\"Weight7\")\n",
    "b7 = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias7\")\n",
    "hypot7 = tf.sigmoid(tf.matmul(hypot6 , W2) + b2)\n",
    "\n",
    "cost = tf.reduce_mean(y * tf.log*(hypot7) + (1-y)*tf.log(1-hypot7))\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 예측\n",
    "pred = tf.cast(hypot7 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a = aess.run([train, hypo7t, pred, accuracy],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_data = np.array([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],\n",
    "                  [1,1,0], [1,0,1], [1,1,1]], dtype=np.float32)\n",
    "\n",
    "y_data = np.arry([[0], [1], [1], [1], [1], [1], [1], [0]],dtype=np.float32)\n",
    "\n",
    "# 입력값 : X, y\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "# 레이어 1\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([3,10])tf.float32, name=\"Weight1\") # 3개 입력 10개 출력\n",
    "    b1 = tf.Variable(tf.random_normal([10])tf.float32, name=\"bias1\")     # 출력의 개수는 적절하게 튜닝\n",
    "    hypot1 = tf.sigmoid(tf.matmul(X , W1) + b1)\n",
    "    \n",
    "    tf.summary.histogram(\"weight1\", W1)\n",
    "    tf.summary.histogram(\"bias1\", b1)      \n",
    "    tf.summary.histogram(\"layer1\", hypot1) \n",
    "    \n",
    "    \n",
    "# 레이어 2\n",
    "with tf.name_scope(\"layer1\"):\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([10,1])tf.float32, name=\"Weight2\")\n",
    "    b2 = tf.Variable(tf.random_normal([1])tf.float32, name=\"bias2\")\n",
    "    hypot2 = tf.sigmoid(tf.matmul(hypot1 , W2) + b2)\n",
    "\n",
    "    tf.summary.histogram(\"weight2\", W2)\n",
    "    tf.summary.histogram(\"bias2\", b2)      \n",
    "    tf.summary.histogram(\"layer2\", hypot2) \n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    cost = tf.reduce_mean(y * tf.log*(hypot2) + (1-y)*tf.log(1-hypot2))\n",
    "    tf.summary.scalar(\"Cost\",cost) # 시각화를 위한 요약\n",
    "\n",
    "train = tf.train.GradientDescentOPtimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 예측\n",
    "pred = tf.cast(hypot2 > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,y), dtype=tf.float32))\n",
    "tf.summary.scalar(\"Accuracy\",accuracy) # 텐서보드를 이용한 시각화를 위한 요약\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    # 파일로 저장\n",
    "    writer = tf.summary.FileWriter(\"log_dir2/alpha01\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    for step in range(1000):\n",
    "        _, h, p, a, summary = aess.run([train, hypot2, pred, accuracy, merged_summary],\n",
    "                             feed_dict={X:x_data, y:y_data})\n",
    "        writer.add_summmary(summary, global_step=step)\n",
    "    print(\"가설 :{}\\n 예측 : {}\\n정확도 : {}\".format(h, p, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate tf1 --> tensorboard --logdir="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU : Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.set_random_seed(777) # 랜덤값 고정\n",
    "mnist = input_data.read_data_sets(\"../acorn machine learing/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placehole(tf.float32, shap=[None, 784])\n",
    "tf.placehole(tf.float32, shap=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([None, 10]))\n",
    "b = tf.Variable(tf.random_normal([None, 10]))\n",
    "\n",
    "\n",
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit,labels))\n",
    "train = tf.train.GradientDescentOpimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(hypot, 1), tf.argmax(y, 1))\n",
    "accuacy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-122fae2a0ae3>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-122fae2a0ae3>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    for i in range(total_batch):\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variable_initializer())\n",
    "\n",
    "training_epochs = 5\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs.batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run(train, feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"epoch :\", (epoch +1), \" cost :\",avg_cost)\n",
    "    \n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정확도 :\", sess.run(accuracy, feed_dict = {X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Xavier 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placehole(tf.float32, shap=[None, 784])\n",
    "tf.placehole(tf.float32, shap=[None, 10])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([265]))\n",
    "logit1 = tf.matmul(X, W) + b\n",
    "hypot1 = tf.nn.softmax(logit1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[265, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([265, 265]))\n",
    "logit2 = tf.matmul(hypot1, W) + b\n",
    "hypot2 = tf.nn.softmax(logit2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[784, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([None, 265]))\n",
    "logit3 = tf.matmul(hypot2, W) + b\n",
    "hypot3 = tf.nn.softmax(logit3)\n",
    "\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[265, 10], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([265, 10]))\n",
    "logit4 = tf.matmul(hypot3, W) + b\n",
    "hypot4 = tf.nn.softmax(logit3)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit4,labels))\n",
    "train = tf.train.GradientDescentOpimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hyp4t, 1), tf.argmax(y, 1))\n",
    "accuacy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variable_initializer())\n",
    "\n",
    "training_epochs = 5\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs.batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run(train, feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"epoch :\", (epoch +1), \" cost :\",avg_cost)\n",
    "    \n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout : 과적합 해결 방안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placehole(tf.float32, shap=[None, 784])\n",
    "tf.placehole(tf.float32, shap=[None, 10])\n",
    "\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([265]))\n",
    "logit1 = tf.matmul(X, W) + b\n",
    "hypot1 = tf.nn.softmax(logit1)\n",
    "hypot1 = tf.nn.dropout(hypot1, keep_prob=prob) # keep_prob=prob :얼마의 데이터로 학습 할건지\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[265, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([265, 265]))\n",
    "logit2 = tf.matmul(hypot1, W) + b\n",
    "hypot2 = tf.nn.softmax(logit2)\n",
    "hypot2 = tf.nn.dropout(hypot2, keep_prob=prob)\n",
    "\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[784, 265], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([None, 265]))\n",
    "logit3 = tf.matmul(hypot2, W) + b\n",
    "hypot3 = tf.nn.softmax(logit3)\n",
    "hypot3 = tf.nn.dropout(hypot3, keep_prob=prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[265, 10], \n",
    "                   initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([265, 10]))\n",
    "logit4 = tf.matmul(hypot3, W) + b\n",
    "hypot4 = tf.nn.softmax(logit3)\n",
    "hypot4 = tf.nn.dropout(hypot4, keep_prob=prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit4,labels))\n",
    "train = tf.train.GradientDescentOpimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hyp4t, 1), tf.argmax(y, 1))\n",
    "accuacy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variable_initializer())\n",
    "\n",
    "training_epochs = 5\n",
    "batch_size = 200\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs.batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run(train, feed_dict={X:batch_xs, y:batch_ys}, \n",
    "                       prob:0.7) # 데이터의 70%만으로 훈련\n",
    "        avg_cost += c/total_batch\n",
    "    print(\"epoch :\", (epoch +1), \" cost :\",avg_cost)\n",
    "\n",
    "print(\"End\")\n",
    "print(\"정확도 :\", sess.run(accuracy sess.run(train, feed_dict={X:mnist_test.images,\n",
    "                                                            y:mnist.test.labels},\n",
    "                                                              prob:1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
